{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasExample.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm8tMXW901_F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99663bef-5bd0-485d-fb45-37e27fd4fe19"
      },
      "source": [
        "import keras\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP3LwAxE6IA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "86f13cb4-2448-44fc-fc60-6d97619a50d6"
      },
      "source": [
        "num_of_classes = 10\n",
        "\n",
        "(x_train, y_train) , (x_test,y_test) = mnist.load_data()\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_of_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_of_classes)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwaIwMRQ6c5k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "7f6a39a7-aa74-4e69-99b6-ea54d31f71c4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "i = random.randint(0,40000)\n",
        "\n",
        "plt.imshow(x_train[i], cmap = \"gray\")\n",
        "print(y_train[i])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/EBQhB8IivADQRF+ICjCDwRF+IGg/gt7KFIneT+rNAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9FuBNo97AXq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "14fc4173-cfe2-4269-ac4f-884ac9f094a6"
      },
      "source": [
        "x_train = x_train.reshape(60000, 28,28,1).astype(\"float32\")\n",
        "x_test = x_test.reshape(10000,28,28,1).astype(\"float32\")\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print(x_train.shape[0])\n",
        "print(x_test.shape[0])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPfBtfWL8VLU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "4b5d4f64-c4f9-434b-952a-92c05f7aa58e"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size = [3,3], input_shape = [28,28,1], activation = \"relu\"))\n",
        "model.add(Conv2D(64, kernel_size = [3,3], activation = \"relu\"))\n",
        "model.add(MaxPooling2D(pool_size =3))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10,activation = \"relu\"))\n",
        "model.add(keras.layers.Activation(\"softmax\"))\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0706 11:44:41.833690 140437456574336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0706 11:44:41.885864 140437456574336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0706 11:44:41.895900 140437456574336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0706 11:44:41.951021 140437456574336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0706 11:44:41.954980 140437456574336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0706 11:44:41.966881 140437456574336 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoF4UYYMAvha",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "5048c7a1-955a-4d5b-9637-c2ba4e9898b7"
      },
      "source": [
        "model.compile(loss = keras.losses.categorical_crossentropy,\n",
        "             optimizer = keras.optimizers.Adadelta(),\n",
        "              metrics = [\"accuracy\"])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0706 11:44:43.120586 140437456574336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0706 11:44:43.132202 140437456574336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AmY9VfCC0nf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "5b101066-b2fd-42e7-c712-7c6f3ac7a31f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               524416    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 544,522\n",
            "Trainable params: 544,522\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acFJ8oUgDAe_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "a6fc4ffc-e48c-4ee9-f48b-6c9fb3cea7fe"
      },
      "source": [
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "\n",
        "\n",
        "tbc = TensorBoardColab()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://d076dbbd.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOFz1IwqEgUJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9efc34d-9b85-4cb1-a3dd-42abed9a0743"
      },
      "source": [
        "my_batch_size = 128\n",
        "model.fit(x_train, y_train,\n",
        "         batch_size = my_batch_size,\n",
        "         epochs = 100,\n",
        "         verbose = 1,\n",
        "         validation_data = (x_test,y_test),\n",
        "         callbacks = [TensorBoardColabCallback(tbc)])\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose = 0)\n",
        "print(\"Test loss {0}\".format(score[0]))\n",
        "print(\"Test accuracy {0}\".format(score[1]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0457 - acc: 0.9869 - val_loss: 0.0285 - val_acc: 0.9907\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0409 - acc: 0.9872 - val_loss: 0.0284 - val_acc: 0.9913\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0372 - acc: 0.9889 - val_loss: 0.0279 - val_acc: 0.9908\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0340 - acc: 0.9903 - val_loss: 0.0250 - val_acc: 0.9920\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0331 - acc: 0.9902 - val_loss: 0.0246 - val_acc: 0.9920\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0315 - acc: 0.9906 - val_loss: 0.0264 - val_acc: 0.9922\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0294 - acc: 0.9911 - val_loss: 0.0258 - val_acc: 0.9918\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0288 - acc: 0.9913 - val_loss: 0.0273 - val_acc: 0.9922\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0269 - acc: 0.9914 - val_loss: 0.0264 - val_acc: 0.9924\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0288 - acc: 0.9917 - val_loss: 0.0282 - val_acc: 0.9917\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.0253 - acc: 0.9919 - val_loss: 0.0263 - val_acc: 0.9924\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0257 - acc: 0.9923 - val_loss: 0.0274 - val_acc: 0.9916\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0244 - acc: 0.9922 - val_loss: 0.0272 - val_acc: 0.9921\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0239 - acc: 0.9926 - val_loss: 0.0247 - val_acc: 0.9927\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0234 - acc: 0.9928 - val_loss: 0.0240 - val_acc: 0.9930\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0219 - acc: 0.9933 - val_loss: 0.0280 - val_acc: 0.9923\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0232 - acc: 0.9930 - val_loss: 0.0270 - val_acc: 0.9923\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0212 - acc: 0.9933 - val_loss: 0.0250 - val_acc: 0.9930\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0217 - acc: 0.9937 - val_loss: 0.0285 - val_acc: 0.9925\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0214 - acc: 0.9935 - val_loss: 0.0276 - val_acc: 0.9923\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0220 - acc: 0.9934 - val_loss: 0.0238 - val_acc: 0.9930\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0219 - acc: 0.9935 - val_loss: 0.0256 - val_acc: 0.9929\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0204 - acc: 0.9939 - val_loss: 0.0276 - val_acc: 0.9933\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0208 - acc: 0.9938 - val_loss: 0.0257 - val_acc: 0.9927\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0222 - acc: 0.9932 - val_loss: 0.0237 - val_acc: 0.9928\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0221 - acc: 0.9939 - val_loss: 0.0261 - val_acc: 0.9926\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0207 - acc: 0.9939 - val_loss: 0.0247 - val_acc: 0.9924\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0209 - acc: 0.9933 - val_loss: 0.0249 - val_acc: 0.9924\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0208 - acc: 0.9935 - val_loss: 0.0280 - val_acc: 0.9938\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0202 - acc: 0.9938 - val_loss: 0.0277 - val_acc: 0.9923\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0192 - acc: 0.9944 - val_loss: 0.0229 - val_acc: 0.9931\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0184 - acc: 0.9944 - val_loss: 0.0264 - val_acc: 0.9930\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0181 - acc: 0.9945 - val_loss: 0.0315 - val_acc: 0.9922\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0193 - acc: 0.9943 - val_loss: 0.0282 - val_acc: 0.9929\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0177 - acc: 0.9949 - val_loss: 0.0253 - val_acc: 0.9930\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0200 - acc: 0.9939 - val_loss: 0.0253 - val_acc: 0.9940\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0181 - acc: 0.9945 - val_loss: 0.0310 - val_acc: 0.9927\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0185 - acc: 0.9947 - val_loss: 0.0279 - val_acc: 0.9931\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0189 - acc: 0.9943 - val_loss: 0.0272 - val_acc: 0.9929\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0178 - acc: 0.9947 - val_loss: 0.0278 - val_acc: 0.9933\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0184 - acc: 0.9944 - val_loss: 0.0271 - val_acc: 0.9933\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0181 - acc: 0.9943 - val_loss: 0.0259 - val_acc: 0.9932\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0190 - acc: 0.9943 - val_loss: 0.0258 - val_acc: 0.9931\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0185 - acc: 0.9943 - val_loss: 0.0279 - val_acc: 0.9925\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0181 - acc: 0.9944 - val_loss: 0.0278 - val_acc: 0.9927\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0161 - acc: 0.9949 - val_loss: 0.0277 - val_acc: 0.9933\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0164 - acc: 0.9952 - val_loss: 0.0263 - val_acc: 0.9933\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0174 - acc: 0.9950 - val_loss: 0.0252 - val_acc: 0.9940\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0172 - acc: 0.9947 - val_loss: 0.0279 - val_acc: 0.9930\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0172 - acc: 0.9949 - val_loss: 0.0283 - val_acc: 0.9930\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.0165 - acc: 0.9950 - val_loss: 0.0277 - val_acc: 0.9927\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0176 - acc: 0.9947 - val_loss: 0.0254 - val_acc: 0.9926\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0163 - acc: 0.9952 - val_loss: 0.0254 - val_acc: 0.9933\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0173 - acc: 0.9951 - val_loss: 0.0247 - val_acc: 0.9936\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0166 - acc: 0.9949 - val_loss: 0.0250 - val_acc: 0.9937\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0147 - acc: 0.9955 - val_loss: 0.0276 - val_acc: 0.9931\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0154 - acc: 0.9954 - val_loss: 0.0285 - val_acc: 0.9935\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0163 - acc: 0.9949 - val_loss: 0.0263 - val_acc: 0.9935\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0145 - acc: 0.9956 - val_loss: 0.0287 - val_acc: 0.9922\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0158 - acc: 0.9953 - val_loss: 0.0264 - val_acc: 0.9938\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0150 - acc: 0.9954 - val_loss: 0.0301 - val_acc: 0.9936\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0152 - acc: 0.9955 - val_loss: 0.0254 - val_acc: 0.9936\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0161 - acc: 0.9953 - val_loss: 0.0306 - val_acc: 0.9937\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0151 - acc: 0.9955 - val_loss: 0.0318 - val_acc: 0.9929\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0147 - acc: 0.9955 - val_loss: 0.0276 - val_acc: 0.9935\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0145 - acc: 0.9958 - val_loss: 0.0299 - val_acc: 0.9921\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0147 - acc: 0.9959 - val_loss: 0.0288 - val_acc: 0.9938\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0156 - acc: 0.9957 - val_loss: 0.0307 - val_acc: 0.9937\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0142 - acc: 0.9953 - val_loss: 0.0282 - val_acc: 0.9931\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0159 - acc: 0.9953 - val_loss: 0.0290 - val_acc: 0.9932\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0144 - acc: 0.9956 - val_loss: 0.0323 - val_acc: 0.9937\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0133 - acc: 0.9957 - val_loss: 0.0280 - val_acc: 0.9933\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0146 - acc: 0.9955 - val_loss: 0.0322 - val_acc: 0.9933\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0126 - acc: 0.9962 - val_loss: 0.0320 - val_acc: 0.9926\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0151 - acc: 0.9954 - val_loss: 0.0329 - val_acc: 0.9932\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0148 - acc: 0.9957 - val_loss: 0.0263 - val_acc: 0.9933\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0149 - acc: 0.9956 - val_loss: 0.0334 - val_acc: 0.9935\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0128 - acc: 0.9962 - val_loss: 0.0294 - val_acc: 0.9938\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0128 - acc: 0.9962 - val_loss: 0.0295 - val_acc: 0.9936\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0138 - acc: 0.9960 - val_loss: 0.0296 - val_acc: 0.9928\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0132 - acc: 0.9958 - val_loss: 0.0308 - val_acc: 0.9928\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0123 - acc: 0.9961 - val_loss: 0.0356 - val_acc: 0.9938\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0127 - acc: 0.9962 - val_loss: 0.0305 - val_acc: 0.9943\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0128 - acc: 0.9964 - val_loss: 0.0286 - val_acc: 0.9944\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0137 - acc: 0.9963 - val_loss: 0.0305 - val_acc: 0.9944\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0131 - acc: 0.9961 - val_loss: 0.0272 - val_acc: 0.9937\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0107 - acc: 0.9965 - val_loss: 0.0304 - val_acc: 0.9937\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0122 - acc: 0.9965 - val_loss: 0.0283 - val_acc: 0.9941\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 9s 153us/step - loss: 0.0131 - acc: 0.9960 - val_loss: 0.0285 - val_acc: 0.9936\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.0130 - acc: 0.9966 - val_loss: 0.0270 - val_acc: 0.9942\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 8s 136us/step - loss: 0.0118 - acc: 0.9963 - val_loss: 0.0270 - val_acc: 0.9942\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0120 - acc: 0.9962 - val_loss: 0.0348 - val_acc: 0.9929\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.0122 - acc: 0.9964 - val_loss: 0.0310 - val_acc: 0.9932\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0128 - acc: 0.9964 - val_loss: 0.0292 - val_acc: 0.9938\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0117 - acc: 0.9966 - val_loss: 0.0345 - val_acc: 0.9930\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.0131 - acc: 0.9963 - val_loss: 0.0297 - val_acc: 0.9937\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.0119 - acc: 0.9965 - val_loss: 0.0280 - val_acc: 0.9932\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0120 - acc: 0.9961 - val_loss: 0.0317 - val_acc: 0.9934\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0132 - acc: 0.9960 - val_loss: 0.0287 - val_acc: 0.9935\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0125 - acc: 0.9963 - val_loss: 0.0293 - val_acc: 0.9940\n",
            "Test loss 0.02929705031307781\n",
            "Test accuracy 0.994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqF8F9J9F9za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}