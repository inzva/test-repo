{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions download -c facial-keypoints-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if keypoint dataset is unzipped\n",
    "#!unzip facial-keypoints-detection.zip\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if training is unzipped\n",
    "#!unzip training.zip\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I took this kaggle problem\n",
    "# https://www.kaggle.com/karanjakhar/facial-keypoint-detection\n",
    "\n",
    "import pandas as pd\n",
    "# from google.colab import drive\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/facial_keypoints/training.csv') \n",
    "print(data.columns)\n",
    "print(data.head())\n",
    "print(data.isnull().any().value_counts())\n",
    "data.fillna(method = 'ffill',inplace = True)\n",
    "print(data.isnull().any().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_data = len(data)\n",
    "pixel_list = []\n",
    "for i in range(num_train_data):\n",
    "    row = data['Image'][i].split(' ')\n",
    "    pixel = ['0' if x == '' else x for x in row] # handling empty image pixels\n",
    "    pixel_list.append(pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images = data['Image'].replace(r'^\\s*$', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pytorch takes channels in the second dimension. For that, I swap axes (dimensions)\n",
    "image_tensor = np.array(pixel_list, dtype = 'float')\n",
    "print(np.shape(image_tensor))\n",
    "image_tensor = image_tensor.reshape(-1, 96, 96, 1)\n",
    "image_tensor = np.swapaxes(image_tensor, 2, 3)\n",
    "image_tensor = np.swapaxes(image_tensor, 1, 2)\n",
    "print(np.shape(image_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data.drop('Image',axis = 1)\n",
    "\n",
    "label_list = []\n",
    "for i in range(num_train_data):\n",
    "    label = labels.iloc[i,:]\n",
    "    label_list.append(label)\n",
    "label_tensor = np.array(label_list,dtype = 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import Circle\n",
    "\n",
    "index = random.randint(0,1000)\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.imshow(image_tensor[index].reshape(96,96),cmap='gray')\n",
    "\n",
    "for xx, yy in label_tensor[index].reshape((15,2)):\n",
    "    circ = Circle((xx,yy),2,color='red')\n",
    "    ax.add_patch(circ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 6000\n",
    "img_and_label = []\n",
    "for i in range(train_len):\n",
    "    img_and_label.append([image_tensor[i], label_tensor[i]])\n",
    "\n",
    "# we use Dataloader objects in pytorch to easily iterate on our dataset while performing training loops\n",
    "train_loader = torch.utils.data.DataLoader(img_and_label, shuffle=True, batch_size=500)\n",
    "img1, lbl1 = next(iter(train_loader))\n",
    "print(\"first training batch: \\n\" + \"input shape: \" + str(img1.shape) + \"\\n\" + \"label shape: \" + str(lbl1.shape))\n",
    "\n",
    "test_data = []\n",
    "for i in range(train_len, num_train_data): # since we have no labels for real test data!\n",
    "    test_data.append([image_tensor[i], label_tensor[i]])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=500)\n",
    "test1, tlbl1 = next(iter(test_loader))\n",
    "print(\"test batch: \\n\" + \"input shape: \" + str(test1.shape) + \"\\n\" + \"label shape: \" + str(tlbl1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# we write our networks as class instances. dont forget to inherit from nn.Module\n",
    "class Net(nn.Module):\n",
    "    # we always need an init method to define our output matrices (similar to nodes in graph)\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) #1, 32\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) #32, 64\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        #self.conv3 = nn.Conv2d(16, 32, 5) #64, 128\n",
    "        #self.conv3_bn = nn.BatchNorm2d(32)\n",
    "\n",
    "        #self.conv4 = nn.Conv2d(32, 64, 5) #128, 256\n",
    "        #self.conv4_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 21 * 21, 120)\n",
    "        self.fc1_bn = nn.BatchNorm1d(120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc2_bn = nn.BatchNorm1d(84)\n",
    "        self.fc3 = nn.Linear(84, 30)\n",
    "        \n",
    "    # we always need an forward method to draw our computational graph (similar to completing the graph with edges)\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.max_pool(self.leaky_relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = self.max_pool(self.leaky_relu(self.conv2_bn(self.conv2(x))))\n",
    "        #x = self.leaky_relu(self.conv3_bn(self.conv3(x)))\n",
    "        #x = self.max_pool(self.leaky_relu(self.conv4_bn(self.conv4(x))))\n",
    "\n",
    "        # vectorize (flatten)\n",
    "        x = x.reshape(-1, 64 * 21 * 21)\n",
    "        #x = torch.flatten(x)\n",
    "        #x = torch.reshape(x, (input_shape, -1))\n",
    "        x = torch.sigmoid(self.fc1_bn(self.fc1(x)))        \n",
    "        x = torch.sigmoid(self.fc2_bn(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "inzvaNet = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(inzvaNet.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inzvaNet = inzvaNet.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we get info on our gpu, put it in the variable \"device\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "\n",
    "#we carry our model into gpu\n",
    "inzvaNet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our training loop\n",
    "# check for free memory option -> this code may lead to memory explosion if grads are not cleared, etc.\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # here we use the dataloader object. it performs .next() operation in each iteration of the loop\n",
    "    # we also group our batches with numbers. we do this with enumerate. we do this so we can know in which batch we are \n",
    "    for i, data in enumerate(train_loader, start = 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "\n",
    "        #inputs, labels = data\n",
    "        inputs, labels = data[0].float().to(device), data[1].float().to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = inzvaNet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:    # print every 2000 mini-batches\n",
    "            print('Epoch %d Loss: %.3f' %\n",
    "                  (epoch + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_test = random.randint(0,49)\n",
    "test_batch = next(iter(test_loader))\n",
    "\n",
    "test_batch_data = test_batch[0].float().to(device)\n",
    "test_batch_label = test_batch[1].float().to(device)\n",
    "\n",
    "preds = inzvaNet(test_batch_data).cpu()\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.imshow(test_batch_data[rand_test].cpu().view((96,96)), cmap = 'gray')\n",
    "\n",
    "for xx, yy in preds[rand_test].reshape((15,2)):\n",
    "    circ = Circle((xx, yy), 2, color='red')\n",
    "    ax.add_patch(circ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.set_aspect('equal')\n",
    "ax.imshow(test_batch_data[rand_test].cpu().view((96,96)), cmap = 'gray')\n",
    "\n",
    "for xx, yy in test_batch_label[rand_test].reshape((15,2)):\n",
    "    circ = Circle((xx, yy), 2, color='red')\n",
    "    ax.add_patch(circ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
