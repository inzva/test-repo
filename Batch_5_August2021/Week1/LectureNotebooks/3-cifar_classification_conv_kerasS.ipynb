{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras directly, not using tensorflow: tell it is also possible!\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar-10 using keras\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset check\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualize first training image\n",
    "plt.imshow(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(x_train[0]),np.amin(x_train[0]))\n",
    "print(np.amax(y_train),np.amin(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization and one-hot encoding\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference between sequential and functional\n",
    "# linear-wise layer adding!\n",
    "from keras.layers import Conv2D, BatchNormalization, Dropout, Dense, Flatten, MaxPool2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "inzvaNet = Sequential()\n",
    "\n",
    "inzvaNet.add(BatchNormalization())\n",
    "inzvaNet.add(Conv2D(64,(5,5),activation = 'tanh', padding = 'same'))\n",
    "inzvaNet.add(MaxPool2D())\n",
    "inzvaNet.add(Dropout(0.2))\n",
    "\n",
    "inzvaNet.add(BatchNormalization())\n",
    "inzvaNet.add(Conv2D(128,(5,5),activation = 'tanh', padding = 'same'))\n",
    "inzvaNet.add(MaxPool2D())\n",
    "inzvaNet.add(Dropout(0.2))\n",
    "\n",
    "inzvaNet.add(BatchNormalization())\n",
    "inzvaNet.add(Conv2D(256,(5,5),activation = 'tanh', padding = 'same'))\n",
    "inzvaNet.add(MaxPool2D())\n",
    "inzvaNet.add(Dropout(0.2))\n",
    "\n",
    "inzvaNet.add(Flatten())\n",
    "inzvaNet.add(Dense(10,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just like functional API, optimizer and compile\n",
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr = 0.001)\n",
    "inzvaNet.compile(optimizer = opt,\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inzvaNet.fit(x_train, y_train, batch_size=100, epochs=4, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inzvaNet.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking some predictions of our model\n",
    "randind = int(random.random() * 1000)\n",
    "plt.imshow(x_test[randind])\n",
    "print(np.argmax(inzvaNet.predict(x_test[[randind]])))\n",
    "print(np.argmax(y_test[randind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dataset pre-processing to use in transfer learning\n",
    "# show dataset's first form from kaggle\n",
    "# explain the aim of each function\n",
    "def getFilenames(exts):\n",
    "    fnames = [glob.glob(ext) for ext in exts]\n",
    "    return fnames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_all(curr_list, name, file):\n",
    "    for count, filename in enumerate(curr_list):\n",
    "        dst = name + file + \"_test\" + str(count) + \".jpg\"\n",
    "        src = name + filename\n",
    "        os.rename(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exts = [\"GoT_dataset/train/arya/*.jpg\"]\n",
    "#res = getFilenames(exts)\n",
    "\n",
    "\n",
    "# renaming dataset into an order!\n",
    "# apply twice for both train and test. Change /test/ to /train/ for training data!\n",
    "# change also in rename_all function! _test -> _train!\n",
    "files = [\"arya\", \"cersie\", \"danerys\", \"Jaimie\", \"john\", \"ned stark\", \"peter baelish\", \"sansa\", \"Tyrion\"]\n",
    "for file in files:\n",
    "   curr_list = os.listdir(\"GoT_dataset/test/\"+file)\n",
    "   rename_all(curr_list, \"GoT_dataset/test/\"+file+\"/\", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get name of all images\n",
    "train_exts = [\"./datasets/GoT_dataset/train/*/*.jpg\"]\n",
    "train_res = getFilenames(train_exts)\n",
    "\n",
    "test_exts = [\"./datasets/GoT_dataset/test/*/*.jpg\"]\n",
    "test_res = getFilenames(test_exts)\n",
    "\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling of training data\n",
    "print(len(train_res))\n",
    "train_labels = []\n",
    "for data in train_res:\n",
    "    if data.find(\"arya\") != -1: train_labels.append(0)\n",
    "    if data.find(\"cersie\") != -1: train_labels.append(1)\n",
    "    if data.find(\"danerys\") != -1: train_labels.append(2)\n",
    "    if data.find(\"Jaimie\") != -1: train_labels.append(3)\n",
    "    if data.find(\"john\") != -1: train_labels.append(4)\n",
    "    if data.find(\"ned stark\") != -1: train_labels.append(5)\n",
    "    if data.find(\"peter baelish\") != -1: train_labels.append(6)\n",
    "    if data.find(\"sansa\") != -1: train_labels.append(7)\n",
    "    if data.find(\"Tyrion\") != -1: train_labels.append(8)\n",
    "\n",
    "print(len(train_labels))\n",
    "# print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling of test data\n",
    "print(len(test_res))\n",
    "test_labels = []\n",
    "for data in test_res:\n",
    "    if data.find(\"arya\") != -1: test_labels.append(0)\n",
    "    if data.find(\"cersie\") != -1: test_labels.append(1)\n",
    "    if data.find(\"danerys\") != -1: test_labels.append(2)\n",
    "    if data.find(\"Jaimie\") != -1: test_labels.append(3)\n",
    "    if data.find(\"john\") != -1: test_labels.append(4)\n",
    "    if data.find(\"ned stark\") != -1: test_labels.append(5)\n",
    "    if data.find(\"peter baelish\") != -1: test_labels.append(6)\n",
    "    if data.find(\"sansa\") != -1: test_labels.append(7)\n",
    "    if data.find(\"Tyrion\") != -1: test_labels.append(8)\n",
    "\n",
    "print(len(test_labels))\n",
    "# print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all images using cv2\n",
    "def image_loader(folder):\n",
    "    images = []\n",
    "    for image in folder:\n",
    "        img = cv2.imread(image, 1)\n",
    "        if img is not None:\n",
    "            images.append(img[:, :, ::-1])\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy array conversion\n",
    "train_images = image_loader(train_res)\n",
    "test_images = image_loader(test_res)\n",
    "\n",
    "print(type(train_images))\n",
    "print(type(test_images))\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(type(train_images))\n",
    "print(type(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[1])\n",
    "print(train_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "print(np.amax(train_images[0]), np.amin(train_images[0]))\n",
    "print(np.amax(train_labels), np.amin(train_labels))\n",
    "\n",
    "# need to convert the images into the training size 32x32x3\n",
    "\n",
    "resized_train_images = []\n",
    "for img in train_images:\n",
    "    resized_img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "    resized_train_images.append(resized_img)\n",
    "\n",
    "train_images = np.array(resized_train_images)\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization and one-hot encoding\n",
    "# tell there are many ways to do a task in each api\n",
    "train_images = train_images.astype(\"float32\") / 255.0\n",
    "test_images = test_images.astype(\"float32\") / 255.0\n",
    "train_labels = keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels = keras.utils.to_categorical(test_labels, 10)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# except the last layer, we freeze. We want the network to learn new dataset \n",
    "# with few training steps using previously learned weights.\n",
    "for layer in inzvaNet.layers[:-1]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiler\n",
    "inzvaNet.compile(optimizer = opt,\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training step\n",
    "inzvaNet.fit(train_images, train_labels, batch_size=100, epochs=15, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test data\n",
    "resized_test_images = []\n",
    "for img in test_images:\n",
    "    resized_img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "    resized_test_images.append(resized_img)\n",
    "\n",
    "test_images = np.array(resized_test_images)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "inzvaNet.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking some predictions of our model\n",
    "randind = int(random.random()*104)\n",
    "plt.imshow(test_images[randind])\n",
    "print(np.argmax(inzvaNet.predict(test_images[[randind]])))\n",
    "print(np.argmax(test_labels[randind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
